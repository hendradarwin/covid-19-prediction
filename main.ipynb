{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hendradarwin/covid-19-prediction/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2NWPZfsgDIK"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x # make sure that collab use tensorflow 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 16, 10\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://raw.githubusercontent.com/hendradarwin/covid-19-prediction/master/dataset/total_cases.csv \\\n",
    "    -O /tmp/global_total.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "time_step = []\n",
    "temps = []\n",
    "\n",
    "\n",
    "with open('/tmp/global_total.csv') as csvfile:\n",
    "  reader = csv.reader(csvfile, delimiter=',')\n",
    "  next(reader)\n",
    "  step=0\n",
    "  for row in reader:\n",
    "    temps.append(float(row[1]))\n",
    "    time_step.append(step)\n",
    "    step = step + 1\n",
    "\n",
    "series = np.array(temps)\n",
    "time = np.array(time_step)\n",
    "\n",
    "series_trimmed = series[80:]\n",
    "time_trimmed = time[80:]\n",
    "\n",
    "\n",
    "\n",
    "series = series_trimmed\n",
    "time = time_trimmed\n",
    "\n",
    "split_time = 50\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Raw Data vs Trimmed Data for training\")\n",
    "plot_series(time, series)\n",
    "plot_series(time_trimmed, series_trimmed)\n",
    "\n",
    "print(\"time_trimmed shape = \", time_trimmed.shape)\n",
    "print(\"series_trimmed shape = \", series_trimmed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_train = time_trimmed[:split_time]\n",
    "x_train = series_trimmed[:split_time]\n",
    "time_valid = time_trimmed[split_time:]\n",
    "x_valid = series_trimmed[split_time:]\n",
    "\n",
    "# hyper parameter\n",
    "window_size = 3\n",
    "batch_size = 2\n",
    "shuffle_buffer_size = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ini buat yg pake DNN\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
    "  dataset = dataset.batch(batch_size).prefetch(1)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ini buat yg pake RNN\n",
    "def windowed_dataset_rnn(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "    ds = ds.batch(2).prefetch(1)\n",
    "    forecast = model.predict(ds)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# DNN\n",
    "train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
    "model = tf.keras.models.Sequential([  \n",
    "  tf.keras.layers.Dense(20, input_shape=[window_size], activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# RNN\n",
    "# train_set = windowed_dataset_rnn(x_train, window_size, batch_size, shuffle_buffer_size)\n",
    "# model = tf.keras.models.Sequential([  \n",
    "#   tf.keras.layers.Conv1D(filters=7, kernel_size=5,\n",
    "#                       strides=1, padding=\"causal\",\n",
    "#                       activation=\"relu\",\n",
    "#                       input_shape=[None, 1]),  \n",
    "#   tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "#   tf.keras.layers.LSTM(64, return_sequences=True),                      \n",
    "#   tf.keras.layers.Dense(80, input_shape=[window_size], activation=\"relu\"),\n",
    "#   tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "#   tf.keras.layers.Dense(1),\n",
    "#   tf.keras.layers.Lambda(lambda x: x * 6000000)\n",
    "# ])\n",
    "\n",
    "# lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-9 * 10**(epoch / 20))\n",
    "optimizer = tf.keras.optimizers.SGD(lr=1e-9, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "history = model.fit(train_set, epochs=500) # , callbacks=[lr_schedule]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "# plt.axis([1e-8, 1e-4, 0, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=history.history['loss']\n",
    "\n",
    "epochs=range(len(loss)) # Get number of epochs\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Loss\"])\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ini forecast untuk RNN\n",
    "rnn_forecast = model_forecast(model, series_trimmed[..., np.newaxis], window_size)\n",
    "rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(time_valid, x_valid)\n",
    "plot_series(time_valid, rnn_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ini forecast untuk yg DNN\n",
    "forecast=[]\n",
    "time_forecast = time_valid\n",
    "step = time_forecast[-1]\n",
    "\n",
    "# for time in range(len(series_trimmed) - window_size):\n",
    "#   forecast.append(model.predict(series_trimmed[time:time + window_size][np.newaxis]))\n",
    "\n",
    "for time in range(len(series_trimmed) - window_size):\n",
    "  prediction = model.predict(series_trimmed[time:time + window_size][np.newaxis])\n",
    "  # print(\"forecast at = \", time, \" window dataset =\", series_trimmed[time:time + window_size][np.newaxis], \" is = \", prediction)  \n",
    "  forecast.append(prediction)\n",
    "\n",
    "for future in range (2): # predict for the next 3 days\n",
    "  next_window = []\n",
    "  for r in range(window_size):\n",
    "    next_window.append( forecast[-window_size + r][0].item() ) # use previous prediction data to predict the future  \n",
    "  step = step + 1\n",
    "  time_forecast = np.append(time_forecast, [step])\n",
    "  next_window = np.array(next_window)[np.newaxis]\n",
    "  prediction = model.predict(next_window)\n",
    "  # print(\"next window = \", next_window)\n",
    "  # print(\"next time = \", step)\n",
    "  # print(\"prediction = \", prediction)\n",
    "  forecast.append(prediction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "forecast = forecast[split_time - window_size:]\n",
    "results = np.array(forecast)[:, 0, 0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Validation Data vs Prediction\")\n",
    "plot_series(time_valid, x_valid)\n",
    "plot_series(time_forecast, results)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Raw Data vs Prediction\")\n",
    "plot_series(time_trimmed, series_trimmed)\n",
    "plot_series(time_forecast, results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPPPN7hAJ7+VrnN5D3JSL5G",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "main.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
